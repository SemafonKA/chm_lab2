# Практическая работа №2 по предмету "Численные методы"

Вариант 4: девятидиагональная матрица

## Содержание:

- [Практическая работа №2 по предмету "Численные методы"](#практическая-работа-2-по-предмету-численные-методы)
  - [Содержание:](#содержание)
  - [1. Немного теории](#1-немного-теории)
    - [1.1 Итерационные методы - зачем?](#11-итерационные-методы---зачем)
    - [1.2 В чём разница между методами Якоби и Зейделя?](#12-в-чём-разница-между-методами-якоби-и-зейделя)
    - [1.3 Параметр релаксации методов](#13-параметр-релаксации-методов)
  - [2. Методы Якоби и Зейделя](#2-методы-якоби-и-зейделя)
  - [3. Генератор матриц по заданию](#3-генератор-матриц-по-заданию)
  - [4. Про замер времени работы](#4-про-замер-времени-работы)


---

## 1. Немного теории

### 1.1 Итерационные методы - зачем?

Итерационные методы решения СЛАУ (а именно такими являются методы Якоби и Зейделя) полезны в тех случаях, когда скорость вычислений ставится в приоритет по сравнению с точностью вычислений. Да, итерационные методы решения СЛАУ не могут быть точнее прямых методов, чуда произойти не может. Но что полезно, в отличие от прямых методов, они могут иметь произвольную заданную точность, от чего напрямую зависит скорость их выполнения.

Например, для прямого метода Гаусса сложность при больших матрицах составляет $O(N^3)$, в то время как для метода Якоби и Зейделя - $O(N^2)$ в случае, если число итераций меньше, чем N. Да, всё верно, итерационные методы могут сходиться даже дольше, чем прямые, но это скорее всего означает только то, что для своей задачи вы выбрали неверный метод.

В целом, с ними ограничения схожие, как и с методами $LU$ и $LL^t$: матрица должна быть хорошо обусловленной, и желательно достаточно большой.

### 1.2 В чём разница между методами Якоби и Зейделя?

Разница между ними есть и она довольно маленькая: в методе Зейделя, в отличие от метода Якоби, при расчётах вектора $x$ каждой текущей итерации используются не только значения вектора с прошлой итерации, но и уже посчитанные значения для текущей итерации. Таким образом, в программах это помогает экономить память, и чаще всего ускоряет подсчёт за счёт того, что при подсчёте следующих элементов вектора, берётся невязка с учётом уже подсчитанных сдвинутых элементов вектора, увеличивая точность подсчётов.

Грубо говоря, Зейдель $\ge$ Якоби.

### 1.3 Параметр релаксации методов

**Параметр релаксации** - достаточно скользкий коэффициент, отвечающий, грубо говоря, за интенсивность изменения вектора $x$ в зависимости от невязки системы. Почему же скользкий? Потому, что для каждой задачи его приходится подбирать практически вручную, собственно, в ходе изучения этих методов мы этим и занимались.

В учебнике сказано, что для метода Якоби он может быть в пределах $0 < \omega \le 1$, а для метода Зейделя: $0 < \omega < 2$.

По факту же, поскольку эти границы указаны для симметричных положительно определённых матриц, а мы работаем с несимметричными, эти границы меняются: методя Якоби может сходиться при коэф. релаксации $>1$, а метод Зейделя может расходиться при коэф. $<1.5$ (цифры указаны для примера, в реальности от ситуации к ситуации всё может поменяться. Даже причина такого поведения методов, кто его знает...). 

---

## 2. Методы Якоби и Зейделя

Реализация этих методов находится в каталоге "chm_2" в файлах "main.cpp", "matrix_IO.h", "datatypes.h" и "Chrono_Timer.h" (последний был нужен для замера времени работы методов, об этом позже).

Матрицы хранятся в девятидиагональном виде, для удобства, в каталоге "chm_2/iofiles" есть два каталога с готовыми файлами, которые необходимо просто скопировать в исходную директорию.

После запуски программы, вас в консоли встретит на мой взгляд интуитивно понятный интерфейс для запуски и тестирования.

Для метода Якоби и Зейделя используется одна и та же процедура, разница лишь в передаваемых векторах в неё. Собственно говоря, разница этих методов в этом и состоит. 

Для исследований выделена отдельная процедура. Она исследует за раз один из двух методов на ваш выбор, в диапазоне коэффициентов релаксации опять же на ваш выбор. Тестирование происходит с шагом опять же на ваш выбор (для лабы вроде нужен шаг 0.01). В процессе работы выводит результат вычислений и число итераций на каждой итерации. В конце выводит лучший коэффициент релаксации для данной матрицы относительно числа итераций метода.

## 3. Генератор матриц по заданию

Для упрощения своей жизни был быстренько накидан простенький генератор 9-диагональных матриц. Запускать его можно двумя способами:

1. Передавать размер матрицы и число нулевых диагоналей в параметрах консоли;
2. Вводить эти параметры после запуска программы.

При генерации матрицы, числа выбираются рандомно из набора значений лямбда-функции `getRandNumber` функции `MatrixGen`, эти значения влияют только на внедиагональные элементы - диагональные всегда будут по модулю. Соответственно, если хотите получить положительную или отрицательную матрицу, достаточно поменять знаки значений в этой лямбда-функции.

После генерации матрицы, она выводится в файлы в разреженном формате, а так же в полном (чтобы можно было легко понять её вид и вставить её в excel, например).

В качестве эталонного вектора $x$ выбирается стандартный вектор вида $(1,2,3,\dots) {a}$.

## 4. Про замер времени работы

Про замер времени хотелось бы сказать, что тот замер, что есть в данной программе - некорректен. Почему? Алгоритм считает слишком быстро, погрешность замера времени оказывается больше времени работы метода.

Основные претензии:

- Данные, загружающиеся в программу, могут оставаться в кэше памяти и затем просто загружаться из памяти обратно, тем самым первый запуск будет медленнее остальных;
- Система со своими прерываниями может замедлить выполнение одной попытки, но при этом не замедлить другое выполнение - опять необъективность.

Как исправить:

- Использовать матрицы гораздо большего размера для вычислений (так себе выход);
- Делать для одних и тех же данных и одного и того же метода, например, 1000 повторений, получать их общее время работы, а затем делить это время на 1000. Таким образом получится усреднённое время работы алгоритма;
- Переделать алгоритм под процессорный счётчик числа операций/времени (если такое вообще возможно), чтобы время вообще не зависело от системных прерываний и прочего.

